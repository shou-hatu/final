{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各ライブラリのimport\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     displacement  horsepower  acceleration  model year  origin_1  origin_2  \\\n",
      "0       -0.492207   -0.476018      0.130705    1.537995  0.794448 -0.485824   \n",
      "1       -0.960864   -0.844250     -0.611386    0.747140 -1.258736  2.058359   \n",
      "2       -0.278255    0.203794     -0.054818   -0.043716 -1.258736 -0.485824   \n",
      "3       -0.950675   -0.730948     -0.425863   -0.570953  0.794448 -0.485824   \n",
      "4       -0.960864   -1.099180      0.613064    1.274377 -1.258736 -0.485824   \n",
      "..            ...         ...           ...         ...       ...       ...   \n",
      "194     -1.001616   -1.014203      1.318050    1.010758 -1.258736 -0.485824   \n",
      "195      1.209220    1.081885     -1.056640    0.483521  0.794448 -0.485824   \n",
      "196      1.229596    1.393466     -1.353477   -1.625426  0.794448 -0.485824   \n",
      "197     -0.950675   -1.495737      2.987754    1.010758 -1.258736  2.058359   \n",
      "198     -0.869170   -0.306065     -0.054818   -0.834571 -1.258736  2.058359   \n",
      "\n",
      "     origin_3  manufacturers name_amc  manufacturers name_audi  \\\n",
      "0   -0.493710               -0.295689                -0.100759   \n",
      "1   -0.493710               -0.295689                -0.100759   \n",
      "2    2.025479               -0.295689                -0.100759   \n",
      "3   -0.493710               -0.295689                -0.100759   \n",
      "4    2.025479               -0.295689                -0.100759   \n",
      "..        ...                     ...                      ...   \n",
      "194  2.025479               -0.295689                -0.100759   \n",
      "195 -0.493710               -0.295689                -0.100759   \n",
      "196 -0.493710                3.381937                -0.100759   \n",
      "197 -0.493710               -0.295689                -0.100759   \n",
      "198 -0.493710               -0.295689                -0.100759   \n",
      "\n",
      "     manufacturers name_bmw  ...  manufacturers name_peugeot  \\\n",
      "0                 -0.100759  ...                   -0.100759   \n",
      "1                 -0.100759  ...                   -0.100759   \n",
      "2                 -0.100759  ...                   -0.100759   \n",
      "3                 -0.100759  ...                   -0.100759   \n",
      "4                 -0.100759  ...                   -0.100759   \n",
      "..                      ...  ...                         ...   \n",
      "194               -0.100759  ...                   -0.100759   \n",
      "195               -0.100759  ...                   -0.100759   \n",
      "196               -0.100759  ...                   -0.100759   \n",
      "197               -0.100759  ...                   -0.100759   \n",
      "198               -0.100759  ...                   -0.100759   \n",
      "\n",
      "     manufacturers name_plymouth  manufacturers name_pontiac  \\\n",
      "0                      -0.264372                    -0.16054   \n",
      "1                      -0.264372                    -0.16054   \n",
      "2                      -0.264372                    -0.16054   \n",
      "3                      -0.264372                    -0.16054   \n",
      "4                      -0.264372                    -0.16054   \n",
      "..                           ...                         ...   \n",
      "194                    -0.264372                    -0.16054   \n",
      "195                    -0.264372                    -0.16054   \n",
      "196                    -0.264372                    -0.16054   \n",
      "197                    -0.264372                    -0.16054   \n",
      "198                    -0.264372                    -0.16054   \n",
      "\n",
      "     manufacturers name_renault  manufacturers name_saab  \\\n",
      "0                     -0.123718                -0.100759   \n",
      "1                     -0.123718                -0.100759   \n",
      "2                     -0.123718                -0.100759   \n",
      "3                     -0.123718                -0.100759   \n",
      "4                     -0.123718                -0.100759   \n",
      "..                          ...                      ...   \n",
      "194                   -0.123718                -0.100759   \n",
      "195                   -0.123718                -0.100759   \n",
      "196                   -0.123718                -0.100759   \n",
      "197                   -0.123718                -0.100759   \n",
      "198                   -0.123718                -0.100759   \n",
      "\n",
      "     manufacturers name_subaru  manufacturers name_toyota  \\\n",
      "0                    -0.100759                  -0.275092   \n",
      "1                    -0.100759                  -0.275092   \n",
      "2                    -0.100759                   3.635146   \n",
      "3                    -0.100759                  -0.275092   \n",
      "4                    -0.100759                   3.635146   \n",
      "..                         ...                        ...   \n",
      "194                  -0.100759                  -0.275092   \n",
      "195                  -0.100759                  -0.275092   \n",
      "196                  -0.100759                  -0.275092   \n",
      "197                  -0.100759                  -0.275092   \n",
      "198                  -0.100759                  -0.275092   \n",
      "\n",
      "     manufacturers name_triumph  manufacturers name_volkswagen  \\\n",
      "0                     -0.071067                       -0.28552   \n",
      "1                     -0.071067                        3.50238   \n",
      "2                     -0.071067                       -0.28552   \n",
      "3                     -0.071067                       -0.28552   \n",
      "4                     -0.071067                       -0.28552   \n",
      "..                          ...                            ...   \n",
      "194                   -0.071067                       -0.28552   \n",
      "195                   -0.071067                       -0.28552   \n",
      "196                   -0.071067                       -0.28552   \n",
      "197                   -0.071067                        3.50238   \n",
      "198                   -0.071067                       -0.28552   \n",
      "\n",
      "     manufacturers name_volvo  \n",
      "0                   -0.100759  \n",
      "1                   -0.100759  \n",
      "2                   -0.100759  \n",
      "3                   -0.100759  \n",
      "4                   -0.100759  \n",
      "..                        ...  \n",
      "194                 -0.100759  \n",
      "195                 -0.100759  \n",
      "196                 -0.100759  \n",
      "197                 -0.100759  \n",
      "198                 -0.100759  \n",
      "\n",
      "[199 rows x 33 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37263288257.50674"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重回帰分析\n",
    "#読み込みから標準化まで(trainのみ)\n",
    "#欠損値補完と標準化の間にエンコーディングの操作を入れるとエラーが出てしまったため改善しよう\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_train['horsepower'] = df_train['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train.iloc[24 , 4] = df_train[df_train['displacement'] == 151]['horsepower'].mean(numeric_only=True)\n",
    "#renault 18\n",
    "df_train.iloc[113 , 4] = df_train[(98 <= df_train['displacement']) & (df_train['displacement']<= 102)]['horsepower'].mean(numeric_only=True)\n",
    "#renault lecar deluxe\n",
    "df_train.iloc[145 , 4] = df_train[df_train['displacement'] == 85]['horsepower'].mean(numeric_only=True)\n",
    "#ford pinto\n",
    "df_train.iloc[175 , 4] = df_train[df_train['car name'] == 'ford pinto']['horsepower'].mean(numeric_only=True)\n",
    "\n",
    "#メーカーカラム作成\n",
    "df_split = df_train['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train['manufacturers name'] = df_train['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "\n",
    "#エンコーディング\n",
    "df_number = pd.get_dummies(df_train , columns = ['origin' , 'manufacturers name'] , dtype=int)\n",
    "\n",
    "#標準化\n",
    "#目的変数の標準化は必要ない\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_train_drop = df_number.drop(['id' , 'car name', 'mpg'] , axis = 1)\n",
    "df_train_std = pd.DataFrame(scaler.fit_transform(df_train_drop), columns = df_train_drop.columns)\n",
    "\n",
    "#特徴量の分割\n",
    "features = df_train_std.drop(['cylinders' , 'weight'] , axis = 1)\n",
    "print(features)\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "target = df_train['mpg']\n",
    "#print(df_train_std.describe())\n",
    "#データ分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train , features_test , target_train , target_test = train_test_split(features , target , test_size = 0.2 , random_state = 0)\n",
    "#ライブラリのimport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "#学習と評価\n",
    "model.fit(features_train , target_train)\n",
    "pred = model.predict(features_test).reshape(-1,1)\n",
    "\n",
    "#評価\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(target_test, pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16208455453677.56"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#重回帰分析\n",
    "#読み込みから標準化まで(trainのみ)\n",
    "#欠損値補完と標準化の間にエンコーディングの操作を入れるとエラーが出てしまったため改善しよう\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('train.tsv' , sep = '\\t')\n",
    "df_train['horsepower'] = df_train['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train.iloc[24 , 4] = df_train[df_train['displacement'] == 151]['horsepower'].mean(numeric_only=True)\n",
    "#renault 18\n",
    "df_train.iloc[113 , 4] = df_train[(98 <= df_train['displacement']) & (df_train['displacement']<= 102)]['horsepower'].mean(numeric_only=True)\n",
    "#renault lecar deluxe\n",
    "df_train.iloc[145 , 4] = df_train[df_train['displacement'] == 85]['horsepower'].mean(numeric_only=True)\n",
    "#ford pinto\n",
    "df_train.iloc[175 , 4] = df_train[df_train['car name'] == 'ford pinto']['horsepower'].mean(numeric_only=True)\n",
    "\n",
    "#メーカーカラム作成\n",
    "df_split = df_train['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train['manufacturers name'] = df_train['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "\n",
    "#エンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohencoder = OneHotEncoder(sparse=False , dtype=int)\n",
    "#メーカーごとにone-hot\n",
    "df_train_manufacturers_number= pd.DataFrame(ohencoder.fit_transform(df_train['manufacturers name'].values.reshape(-1,1)) , columns = df_train['manufacturers name'].unique()).astype(int)\n",
    "#国ごとにone-hot\n",
    "df_train_origin_number= pd.DataFrame(ohencoder.fit_transform(df_train['origin'].values.reshape(-1,1)) , columns = ['America' , 'Europe' , 'Japan']).astype(int)\n",
    "#ダミー変数に変換したdfの結合\n",
    "df_train_number = pd.merge(df_train_manufacturers_number , df_train_origin_number , how = 'outer' , right_index = True , left_index=True)\n",
    "df_train = pd.merge(df_train , df_train_number , how = 'outer' , right_index = True , left_index=True)\n",
    "df_train = df_train.dropna(how = 'any')\n",
    "\n",
    "#標準化\n",
    "#目的変数の標準化は必要ない\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_train_drop = df_train.drop(['id' , 'manufacturers name' , 'car name', 'origin', 'mpg'] , axis = 1)\n",
    "df_train_std = pd.DataFrame(scaler.fit_transform(df_train_drop), columns = df_train_drop.columns)\n",
    "\n",
    "#特徴量の分割\n",
    "\n",
    "features = df_train_std.drop(['cylinders' , 'weight'] , axis = 1)\n",
    "target = df_train['mpg']\n",
    "#print(df_train_std.describe())\n",
    "#データ分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train , features_test , target_train , target_test = train_test_split(features , target , test_size = 0.25 , random_state = 0)\n",
    "#ライブラリのimport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "#学習と評価\n",
    "model.fit(features_train , target_train)\n",
    "pred = model.predict(features_test).reshape(-1,1)\n",
    "\n",
    "#評価\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(target_test, pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cylinders  displacement  horsepower    weight  acceleration  model year  \\\n",
      "0    -0.790333     -0.492207   -0.474464 -0.438837      0.130705    1.537995   \n",
      "1    -0.790333     -0.960864   -0.842669 -1.172599     -0.611386    0.747140   \n",
      "2     0.428863     -0.278255    0.205299  0.056452     -0.054818   -0.043716   \n",
      "3    -0.790333     -0.950675   -0.729375 -0.928011     -0.425863   -0.570953   \n",
      "4    -0.790333     -0.960864   -1.097580 -1.019732      0.613064    1.274377   \n",
      "..         ...           ...         ...       ...           ...         ...   \n",
      "194  -0.790333     -1.001616   -1.012610 -0.946355      1.318050    1.010758   \n",
      "195   1.648060      1.209220    1.083326  0.839130     -1.056640    0.483521   \n",
      "196   1.648060      1.229596    1.394884  0.671588     -1.353477   -1.625426   \n",
      "197  -0.790333     -0.950675   -1.494108 -0.671195      2.987754    1.010758   \n",
      "198  -0.790333     -0.869170   -0.304523 -0.756800     -0.054818   -0.834571   \n",
      "\n",
      "     origin_1  origin_2  origin_3  manufacturers name_amc  ...  \\\n",
      "0    0.794448 -0.485824 -0.493710               -0.295689  ...   \n",
      "1   -1.258736  2.058359 -0.493710               -0.295689  ...   \n",
      "2   -1.258736 -0.485824  2.025479               -0.295689  ...   \n",
      "3    0.794448 -0.485824 -0.493710               -0.295689  ...   \n",
      "4   -1.258736 -0.485824  2.025479               -0.295689  ...   \n",
      "..        ...       ...       ...                     ...  ...   \n",
      "194 -1.258736 -0.485824  2.025479               -0.295689  ...   \n",
      "195  0.794448 -0.485824 -0.493710               -0.295689  ...   \n",
      "196  0.794448 -0.485824 -0.493710                3.381937  ...   \n",
      "197 -1.258736  2.058359 -0.493710               -0.295689  ...   \n",
      "198 -1.258736  2.058359 -0.493710               -0.295689  ...   \n",
      "\n",
      "     manufacturers name_peugeot  manufacturers name_plymouth  \\\n",
      "0                     -0.100759                    -0.264372   \n",
      "1                     -0.100759                    -0.264372   \n",
      "2                     -0.100759                    -0.264372   \n",
      "3                     -0.100759                    -0.264372   \n",
      "4                     -0.100759                    -0.264372   \n",
      "..                          ...                          ...   \n",
      "194                   -0.100759                    -0.264372   \n",
      "195                   -0.100759                    -0.264372   \n",
      "196                   -0.100759                    -0.264372   \n",
      "197                   -0.100759                    -0.264372   \n",
      "198                   -0.100759                    -0.264372   \n",
      "\n",
      "     manufacturers name_pontiac  manufacturers name_renault  \\\n",
      "0                      -0.16054                   -0.123718   \n",
      "1                      -0.16054                   -0.123718   \n",
      "2                      -0.16054                   -0.123718   \n",
      "3                      -0.16054                   -0.123718   \n",
      "4                      -0.16054                   -0.123718   \n",
      "..                          ...                         ...   \n",
      "194                    -0.16054                   -0.123718   \n",
      "195                    -0.16054                   -0.123718   \n",
      "196                    -0.16054                   -0.123718   \n",
      "197                    -0.16054                   -0.123718   \n",
      "198                    -0.16054                   -0.123718   \n",
      "\n",
      "     manufacturers name_saab  manufacturers name_subaru  \\\n",
      "0                  -0.100759                  -0.100759   \n",
      "1                  -0.100759                  -0.100759   \n",
      "2                  -0.100759                  -0.100759   \n",
      "3                  -0.100759                  -0.100759   \n",
      "4                  -0.100759                  -0.100759   \n",
      "..                       ...                        ...   \n",
      "194                -0.100759                  -0.100759   \n",
      "195                -0.100759                  -0.100759   \n",
      "196                -0.100759                  -0.100759   \n",
      "197                -0.100759                  -0.100759   \n",
      "198                -0.100759                  -0.100759   \n",
      "\n",
      "     manufacturers name_toyota  manufacturers name_triumph  \\\n",
      "0                    -0.275092                   -0.071067   \n",
      "1                    -0.275092                   -0.071067   \n",
      "2                     3.635146                   -0.071067   \n",
      "3                    -0.275092                   -0.071067   \n",
      "4                     3.635146                   -0.071067   \n",
      "..                         ...                         ...   \n",
      "194                  -0.275092                   -0.071067   \n",
      "195                  -0.275092                   -0.071067   \n",
      "196                  -0.275092                   -0.071067   \n",
      "197                  -0.275092                   -0.071067   \n",
      "198                  -0.275092                   -0.071067   \n",
      "\n",
      "     manufacturers name_volkswagen  manufacturers name_volvo  \n",
      "0                         -0.28552                 -0.100759  \n",
      "1                          3.50238                 -0.100759  \n",
      "2                         -0.28552                 -0.100759  \n",
      "3                         -0.28552                 -0.100759  \n",
      "4                         -0.28552                 -0.100759  \n",
      "..                             ...                       ...  \n",
      "194                       -0.28552                 -0.100759  \n",
      "195                       -0.28552                 -0.100759  \n",
      "196                       -0.28552                 -0.100759  \n",
      "197                        3.50238                 -0.100759  \n",
      "198                       -0.28552                 -0.100759  \n",
      "\n",
      "[199 rows x 37 columns]\n",
      "0      29.0\n",
      "1      31.9\n",
      "2      19.0\n",
      "3      28.0\n",
      "4      37.7\n",
      "       ... \n",
      "194    40.8\n",
      "195    20.2\n",
      "196    16.0\n",
      "197    43.4\n",
      "198    26.0\n",
      "Name: mpg, Length: 199, dtype: float64\n",
      "      id  cylinders  displacement horsepower  weight  acceleration  \\\n",
      "0      1          6         145.0      76.00  3160.0          19.6   \n",
      "1      2          6         250.0      98.00  3525.0          19.0   \n",
      "2      4          4         119.0      92.00  2434.0          15.0   \n",
      "3      5          6         258.0      110.0  2962.0          13.5   \n",
      "4      6          4          97.0      88.00  2100.0          16.5   \n",
      "..   ...        ...           ...        ...     ...           ...   \n",
      "194  391          4         114.0      91.00  2582.0          14.0   \n",
      "195  392          4         156.0      105.0  2800.0          14.4   \n",
      "196  393          4         111.0      80.00  2155.0          14.8   \n",
      "197  394          8         400.0      180.0  4220.0          11.1   \n",
      "198  397          4          97.0      78.00  1940.0          14.5   \n",
      "\n",
      "     model year  origin                    car name  \n",
      "0            81       2                volvo diesel  \n",
      "1            77       1                ford granada  \n",
      "2            80       3        datsun 510 hatchback  \n",
      "3            71       1  amc hornet sportabout (sw)  \n",
      "4            72       3    toyota corolla 1600 (sw)  \n",
      "..          ...     ...                         ...  \n",
      "194          73       2                  audi 100ls  \n",
      "195          80       1                  dodge colt  \n",
      "196          77       1     buick opel isuzu deluxe  \n",
      "197          77       1       pontiac grand prix lj  \n",
      "198          77       2    volkswagen rabbit custom  \n",
      "\n",
      "[199 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#get_dummiesでエンコードver\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_train_test = pd.concat([df_train , df_test] , axis =0)\n",
    "df_train_test.isnull().sum()\n",
    "\n",
    "df_train_test['horsepower'] = df_train_test['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train_test.iloc[24 , 4] = df_train_test[df_train_test['displacement'] == 151]['horsepower'].mean()\n",
    "#renault 18\n",
    "df_train_test.iloc[113 , 4] = df_train_test[(98 <= df_train_test['displacement']) & (df_train_test['displacement']<= 102)]['horsepower'].mean()\n",
    "#renault lecar deluxe\n",
    "df_train_test.iloc[145 , 4] = df_train_test[df_train_test['displacement'] == 85]['horsepower'].mean()\n",
    "#ford pinto\n",
    "df_train_test.iloc[175 , 4] = df_train_test[df_train_test['car name'] == 'ford pinto']['horsepower'].mean()\n",
    "#ford maverick\n",
    "df_train_test.loc[70 , 'horsepower'] = df_train_test[df_train_test['car name'] == \"ford maverick\"]['horsepower'].mean()\n",
    "#ford mustang cobra\n",
    "df_train_test.loc[112 , 'horsepower'] = df_train_test[df_train_test['displacement'] == 140]['horsepower'].mean()\n",
    "\n",
    "#メーカーカラム作成\n",
    "df_split = df_train_test['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train_test['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train_test['manufacturers name'] = df_train_test['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "\n",
    "#one-hot\n",
    "#get_dummies(扱うdf,columns=カテゴリ変数を含むカラム,dtype=データ型)\n",
    "#元のdfに数値化したカラムを結合してくれるから便利\n",
    "df_number = pd.get_dummies(df_train_test , columns = ['origin' , 'manufacturers name'] , dtype=int)\n",
    "#:199だと198番目までが選択される\n",
    "df_train = df_number.iloc[:199 , :]\n",
    "df_test = df_number.iloc[199: , :]\n",
    "\n",
    "#標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_train_drop = df_train.drop(['id' , 'car name'  , 'mpg'] , axis = 1)\n",
    "df_test_drop = df_test.drop(['id' , 'car name' , 'mpg'] , axis = 1)\n",
    "\n",
    "scaler.fit(df_train_drop)\n",
    "df_train_std= pd.DataFrame(scaler.transform(df_train_drop), columns = df_train_drop.columns)\n",
    "df_test_std = pd.DataFrame(scaler.transform(df_test_drop), columns = df_test_drop.columns)\n",
    "print(df_train_std)\n",
    "\n",
    "#目的変数の分離\n",
    "features_train = df_train_std.drop(['weight' , 'acceleration' ] , axis = 1)\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "target_train = df_train['mpg']\n",
    "print(df_train['mpg'])\n",
    "features_test = df_test_std.drop(['weight' , 'acceleration'] , axis = 1)\n",
    "\n",
    "#学習\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(features_train , target_train)\n",
    "#予測\n",
    "df_pred = pd.DataFrame(model.predict(features_test))\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "print(df_test)\n",
    "df_pred = pd.merge(df_test['id'].astype(int) , df_pred , how = 'outer' , right_index = True , left_index=True)\n",
    "df_pred\n",
    "#評価\n",
    "#multiple regression analysisの頭文字をとってMRA_sample_submit.csv\n",
    "df_pred.to_csv('../MRA_sample_submit.csv' , header = False , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
      "       'acceleration', 'model year', 'origin', 'car name', 'dodge', 'vw',\n",
      "       'toyota', 'pontiac', 'chevrolet', 'oldsmobile', 'bmw', 'mercedes-benz',\n",
      "       'datsun', 'amc', 'renault', 'peugeot', 'ford', 'mercury', 'subaru',\n",
      "       'honda', 'volkswagen', 'saab', 'mazda', 'plymouth', 'opel', 'chevy',\n",
      "       'capri', 'fiat', 'hi', 'audi', 'buick', 'vokswagen', 'volvo', 'triumph',\n",
      "       'America', 'Europe', 'Japan'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['mpg'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m df_test_std \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scaler\u001b[38;5;241m.\u001b[39mtransform(df_test_drop), columns \u001b[38;5;241m=\u001b[39m df_test_drop\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#目的変数の分離\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m features_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train_std\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43macceleration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m target_train \u001b[38;5;241m=\u001b[39m df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     66\u001b[0m features_test \u001b[38;5;241m=\u001b[39m df_test_std\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m'\u001b[39m] , axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6992\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6993\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6994\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['mpg'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#データ読み込みから標準化まで(train,test結合版)\n",
    "#ダミー変数も標準化\n",
    "#目的変数は標準化しない\n",
    "#欠損値補完と標準化の間にエンコーディングの操作を入れるとエラーが出てしまったため改善しよう\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_train_test = pd.concat([df_train , df_test] , axis =0)\n",
    "#print(df_train_test[df_train_test['horsepower'] == \"?\"])\n",
    "df_train_test['horsepower'] = df_train_test['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train.iloc[24 , 4] = df_train_test[df_train_test['displacement'] == 151]['horsepower'].mean()\n",
    "#renault 18\n",
    "df_train.iloc[113 , 4] = df_train_test[(98 <= df_train_test['displacement']) & (df_train_test['displacement']<= 102)]['horsepower'].mean()\n",
    "#renault lecar deluxe\n",
    "df_train.iloc[145 , 4] = df_train_test[df_train_test['displacement'] == 85]['horsepower'].mean()\n",
    "#ford pinto\n",
    "df_train.iloc[175 , 4] = df_train_test[df_train_test['car name'] == 'ford pinto']['horsepower'].mean()\n",
    "#ford maverick\n",
    "df_test.loc[70 , 'horsepower'] = df_train_test[df_train_test['car name'] == \"ford maverick\"]['horsepower'].mean()\n",
    "#ford mustang cobra\n",
    "df_test.loc[112 , 'horsepower'] = df_train_test[df_train_test['displacement'] == 140]['horsepower'].mean()\n",
    "#補完確認\n",
    "#df_train_test[df_train_test['horsepower'].isnull()]\n",
    "#ラベルエンコーディング(train,test結合版)\n",
    "#メーカーカラム作成\n",
    "df_split = df_train['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train_test['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train_test['manufacturers name'] = df_train_test['manufacturers name'].replace({'chevroelt':'chevrolet' , 'toyouta':'toyota'})#カラム名の修正\n",
    "\n",
    "#エンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohencoder = OneHotEncoder(sparse=False , dtype=int)\n",
    "#メーカーごとにone-hot\n",
    "df_manufacturers_number= pd.DataFrame(ohencoder.fit_transform(df_train_test['manufacturers name'].values.reshape(-1,1)) , columns = df_train_test['manufacturers name'].unique()).astype(int)\n",
    "#国ごとにone-hot\n",
    "df_origin_number= pd.DataFrame(ohencoder.fit_transform(df_train_test['origin'].values.reshape(-1,1)) , columns = ['America' , 'Europe' , 'Japan']).astype(int)\n",
    "#ダミー変数に変換したdfの結合\n",
    "df_number = pd.merge(df_manufacturers_number , df_origin_number , how = 'outer' , right_index = True , left_index=True)\n",
    "#df_numberとdf_train_testの結合\n",
    "#右側のデータフレームのインデックスをキーとして、左側のデータフレームを結合する(right_index=True)\n",
    "#右側のデータフレームのインデックスをキーとして、左側のデータフレームを結合する(right_index=True)\n",
    "#left_indexとright_indexの両方をTrueにしないとエラーになってしまった\n",
    "df_train = pd.merge(df_train , df_number , how = 'outer' , right_index = True , left_index=True)\n",
    "df_train = df_train.dropna(how = 'any')\n",
    "print(df_train.columns)\n",
    "df_test = pd.merge(df_test , df_number , how = 'outer' , right_index = True , left_index=True)\n",
    "df_test = df_test.dropna(how = 'any')\n",
    "df_test.head()\n",
    "#標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_train_drop = df_train.drop(['id' , 'car name' , 'origin','mpg'] , axis = 1)\n",
    "df_test_drop = df_test.drop(['id' , 'car name' , 'origin'] , axis = 1)\n",
    "#df_testにmpgカラムがないからdf_trainのfitの計算結果を使えない\n",
    "#別々にfitして標準化した\n",
    "scaler.fit(df_train_drop)\n",
    "df_train_std= pd.DataFrame(scaler.transform(df_train_drop), columns = df_train_drop.columns)\n",
    "df_test_std = pd.DataFrame(scaler.transform(df_test_drop), columns = df_test_drop.columns)\n",
    "\n",
    "#目的変数の分離\n",
    "features_train = df_train_std.drop(['weight' , 'acceleration' , 'mpg' ] , axis = 1)\n",
    "target_train = df_train['mpg']\n",
    "features_test = df_test_std.drop(['weight' , 'acceleration'] , axis = 1)\n",
    "#学習\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100 , random_state = 0)\n",
    "model.fit(features_train , target_train)\n",
    "#予測\n",
    "df_pred = pd.DataFrame(model.predict(features_test))\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_pred = pd.merge(df_test['id'].astype(int) , df_pred , how = 'outer' , right_index = True , left_index=True)\n",
    "df_pred\n",
    "#評価\n",
    "df_pred.to_csv('../RF_sample_submit.csv' , header = False , index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shouh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#データ読み込みから標準化まで(train,test結合版)\n",
    "#欠損値補完と標準化の間にエンコーディングの操作を入れるとエラーが出てしまったため改善しよう\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_train_test = pd.concat([df_train , df_test] , axis =0)\n",
    "#print(df_train_test[df_train_test['horsepower'] == \"?\"])\n",
    "df_train_test['horsepower'] = df_train_test['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train.iloc[24 , 4] = df_train_test[df_train_test['displacement'] == 151]['horsepower'].mean()\n",
    "#renault 18\n",
    "df_train.iloc[113 , 4] = df_train_test[(98 <= df_train_test['displacement']) & (df_train_test['displacement']<= 102)]['horsepower'].mean()\n",
    "#renault lecar deluxe\n",
    "df_train.iloc[145 , 4] = df_train_test[df_train_test['displacement'] == 85]['horsepower'].mean()\n",
    "#ford pinto\n",
    "df_train.iloc[175 , 4] = df_train_test[df_train_test['car name'] == 'ford pinto']['horsepower'].mean()\n",
    "#ford maverick\n",
    "df_test.loc[70 , 'horsepower'] = df_train_test[df_train_test['car name'] == \"ford maverick\"]['horsepower'].mean()\n",
    "#ford mustang cobra\n",
    "df_test.loc[112 , 'horsepower'] = df_train_test[df_train_test['displacement'] == 140]['horsepower'].mean()\n",
    "#補完確認\n",
    "#df_train_test[df_train_test['horsepower'].isnull()]\n",
    "#ラベルエンコーディング(train,test結合版)\n",
    "#メーカーカラム作成\n",
    "df_split = df_train['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train_test['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train_test['manufacturers name'] = df_train_test['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "\n",
    "#エンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohencoder = OneHotEncoder(sparse=False , dtype=int)\n",
    "#メーカーごとにone-hot\n",
    "df_manufacturers_number= pd.DataFrame(ohencoder.fit_transform(df_train_test['manufacturers name'].values.reshape(-1,1)) , columns = df_train_test['manufacturers name'].unique()).astype(int)\n",
    "#国ごとにone-hot\n",
    "df_origin_number= pd.DataFrame(ohencoder.fit_transform(df_train_test['origin'].values.reshape(-1,1)) , columns = ['America' , 'Europe' , 'Japan']).astype(int)\n",
    "#ダミー変数に変換したdfの結合\n",
    "df_number = pd.merge(df_manufacturers_number , df_origin_number , how = 'outer' , right_index = True , left_index=True)\n",
    "\n",
    "#標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_train_drop = df_train.drop(['id' , 'car name' , 'origin'] , axis = 1)\n",
    "df_test_drop = df_test.drop(['id' , 'car name' , 'origin'] , axis = 1)\n",
    "#df_testにmpgカラムがないからdf_trainのfitの計算結果を使えない\n",
    "#別々にfitして標準化した\n",
    "scaler.fit(df_train_drop)\n",
    "df_train_std= pd.DataFrame(scaler.transform(df_train_drop), columns = df_train_drop.columns)\n",
    "scaler.fit(df_test_drop)\n",
    "df_test_std = pd.DataFrame(scaler.transform(df_test_drop), columns = df_test_drop.columns)\n",
    "\n",
    "#df_numberとdf_train_testの結合\n",
    "#右側のデータフレームのインデックスをキーとして、左側のデータフレームを結合する(right_index=True)\n",
    "#右側のデータフレームのインデックスをキーとして、左側のデータフレームを結合する(right_index=True)\n",
    "#left_indexとright_indexの両方をTrueにしないとエラーになってしまった\n",
    "df_train = pd.merge(df_train_std , df_number , how = 'outer' , right_index = True , left_index=True)\n",
    "df_train = df_train.dropna(how = 'any')\n",
    "df_test = pd.merge(df_test_std , df_number , how = 'outer' , right_index = True , left_index=True)\n",
    "df_test = df_test.dropna(how = 'any')\n",
    "df_test.head()\n",
    "\n",
    "#目的変数の分離\n",
    "features_train = df_train.drop(['weight' , 'acceleration' , 'mpg' ] , axis = 1)\n",
    "target_train = df_train['mpg']\n",
    "features_test = df_test.drop(['weight' , 'acceleration'] , axis = 1)\n",
    "#学習\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(features_train , target_train)\n",
    "#予測\n",
    "df_pred = pd.DataFrame(model.predict(features_test))\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_pred = pd.merge(df_test['id'].astype(int) , df_pred , how = 'outer' , right_index = True , left_index=True)\n",
    "df_pred\n",
    "#評価\n",
    "#multiple regression analysisの頭文字をとってMRA_sample_submit.csv\n",
    "df_pred.to_csv('../MRA_sample_submit.csv' , header = False , index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mpg   cylinders  displacement    horsepower        weight  \\\n",
      "count  1.990000e+02  199.000000  1.990000e+02  1.990000e+02  1.990000e+02   \n",
      "mean  -2.588661e-16    0.000000 -4.016887e-17  1.517491e-16 -1.338962e-16   \n",
      "std    1.002522e+00    1.002522  1.002522e+00  1.002522e+00  1.002522e+00   \n",
      "min   -1.967979e+00   -1.399932 -1.144251e+00 -1.553318e+00 -1.554154e+00   \n",
      "25%   -8.108763e-01   -0.790333 -8.691699e-01 -7.457911e-01 -8.148899e-01   \n",
      "50%   -3.947458e-02   -0.790333 -4.412662e-01 -3.066095e-01 -2.223776e-01   \n",
      "75%    7.962106e-01    0.428863  6.794342e-01  3.309121e-01  6.636392e-01   \n",
      "max    2.609005e+00    1.648060  2.757824e+00  3.376849e+00  2.759139e+00   \n",
      "\n",
      "       acceleration    model year       dodge          vw      toyota  ...  \\\n",
      "count  1.990000e+02  1.990000e+02  199.000000  199.000000  199.000000  ...   \n",
      "mean  -2.454764e-16  1.687093e-15    0.080402    0.010050    0.010050  ...   \n",
      "std    1.002522e+00  1.002522e+00    0.272600    0.099997    0.099997  ...   \n",
      "min   -2.652135e+00 -1.625426e+00    0.000000    0.000000    0.000000  ...   \n",
      "25%   -6.113858e-01 -8.345711e-01    0.000000    0.000000    0.000000  ...   \n",
      "50%   -5.481776e-02 -4.371563e-02    0.000000    0.000000    0.000000  ...   \n",
      "75%    5.574071e-01  1.010758e+00    0.000000    0.000000    0.000000  ...   \n",
      "max    2.987754e+00  1.537995e+00    1.000000    1.000000    1.000000  ...   \n",
      "\n",
      "             fiat          hi        audi       buick   vokswagen       volvo  \\\n",
      "count  199.000000  199.000000  199.000000  199.000000  199.000000  199.000000   \n",
      "mean     0.010050    0.070352    0.005025    0.005025    0.050251    0.010050   \n",
      "std      0.099997    0.256384    0.070888    0.070888    0.219014    0.099997   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "          triumph     America      Europe       Japan  \n",
      "count  199.000000  199.000000  199.000000  199.000000  \n",
      "mean     0.020101    0.613065    0.190955    0.195980  \n",
      "std      0.140698    0.488277    0.394045    0.397954  \n",
      "min      0.000000    0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000    0.000000  \n",
      "50%      0.000000    1.000000    0.000000    0.000000  \n",
      "75%      0.000000    1.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 40 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4146033228104701"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainのみで学習評価\n",
    "print(df_train.describe())\n",
    "#特徴量の分割\n",
    "features = df_train.drop(['mpg','cylinders' , 'weight'] , axis = 1)\n",
    "target = df_train['mpg']\n",
    "#データ分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train , features_test , target_train , target_test = train_test_split(features , target , test_size = 0.25 , random_state = 0)\n",
    "#ライブラリのimport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "#学習と評価\n",
    "model.fit(features_train , target_train)\n",
    "pred = model.predict(features_test)\n",
    "#評価\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(target_test, pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
