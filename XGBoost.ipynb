{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各ライブラリのimport\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0805420080889037"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost\n",
    "#読み込みから標準化まで(trainのみ)\n",
    "#欠損値補完と標準化の間にエンコーディングの操作を入れるとエラーが出てしまったため改善しよう\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_train['horsepower'] = df_train['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train.iloc[24 , 4] = df_train[df_train['displacement'] == 151]['horsepower'].mean(numeric_only=True)\n",
    "#renault 18\n",
    "df_train.iloc[113 , 4] = df_train[(98 <= df_train['displacement']) & (df_train['displacement']<= 102)]['horsepower'].mean(numeric_only=True)\n",
    "#renault lecar deluxe\n",
    "df_train.iloc[145 , 4] = df_train[df_train['displacement'] == 85]['horsepower'].mean(numeric_only=True)\n",
    "#ford pinto\n",
    "df_train.iloc[175 , 4] = df_train[df_train['car name'] == 'ford pinto']['horsepower'].mean(numeric_only=True)\n",
    "#pwrカラム作成\n",
    "#df_train['pwr'] = df_train['weight']/df_train['horsepower']\n",
    "#メーカーカラム作成\n",
    "df_split = df_train['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train['manufacturers name'] = df_train['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "#エンコーディング\n",
    "df_number = pd.get_dummies(df_train , columns = ['origin' , 'manufacturers name'] , dtype=int)\n",
    "#特徴量の分割\n",
    "features = df_number.drop(['id' , 'cylinders' ,'weight' , 'car name' , 'mpg'] , axis = 1)\n",
    "#print(features)\n",
    "target = df_train['mpg']\n",
    "#データ分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train , features_test , target_train , target_test = train_test_split(features , target , test_size = 0.25 , random_state = 0)\n",
    "#学習\n",
    "from xgboost import XGBRegressor\n",
    "#early_stopping_roundsは学習回数を適切なタイミングで打ち止めるための仕組み\n",
    "model = XGBRegressor(n_estimators = 100)\n",
    "model.fit(features_train , target_train)\n",
    "pred = model.predict(features_test)\n",
    "#評価\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(target_test, pred)) \n",
    "#pwrカラムなし,horsepowerあり,accelerationあり;2.92\n",
    "#pwrカラムなし,horsepowerなしaccelerationあり;3.098\n",
    "#pwrカラムあり,horsepowerなし,accelerationあり;2.996\n",
    "#pwrカラムあり,horsepowerなし,accelerationなし;3.390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6592625087884603"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost\n",
    "#gridsearch\n",
    "#読み込みから標準化まで(trainのみ)\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_train['horsepower'] = df_train['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train.iloc[24 , 4] = df_train[df_train['displacement'] == 151]['horsepower'].mean(numeric_only=True)\n",
    "#renault 18\n",
    "df_train.iloc[113 , 4] = df_train[(98 <= df_train['displacement']) & (df_train['displacement']<= 102)]['horsepower'].mean(numeric_only=True)\n",
    "#renault lecar deluxe\n",
    "df_train.iloc[145 , 4] = df_train[df_train['displacement'] == 85]['horsepower'].mean(numeric_only=True)\n",
    "#ford pinto\n",
    "df_train.iloc[175 , 4] = df_train[df_train['car name'] == 'ford pinto']['horsepower'].mean(numeric_only=True)\n",
    "#pwrカラム作成\n",
    "df_train['pwr'] = df_train['weight']/df_train['horsepower']\n",
    "#メーカーカラム作成\n",
    "df_split = df_train['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train['manufacturers name'] = df_train['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "#エンコーディング\n",
    "df_number = pd.get_dummies(df_train , columns = ['origin' , 'manufacturers name'] , dtype=int)\n",
    "#標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_train_drop = df_number.drop(['mpg','id' , 'car name' , 'weight' , 'cylinders' , 'horsepower'] , axis = 1)\n",
    "df_train_std = pd.DataFrame(scaler.fit_transform(df_train_drop), columns = df_train_drop.columns)\n",
    "\n",
    "\n",
    "#特徴量の分割\n",
    "features = df_train_std\n",
    "target = df_train['mpg']\n",
    "#データ分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train , features_test , target_train , target_test = train_test_split(features , target , test_size = 0.25 , random_state = 0)\n",
    "#学習\n",
    "from xgboost import XGBRegressor\n",
    "#early_stopping_roundsは学習回数を適切なタイミングで打ち止めるための仕組み\n",
    "model = XGBRegressor()\n",
    "#gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 最終的なパラメータ範囲\n",
    "cv_params = {'n_estimators': [20,40,60,80,100],\n",
    "             'learning_rate': [0.01, 0.03, 0.1, 0.3],#学習率(0～1)\n",
    "             'min_child_weight': [2, 4, 6, 8],#決定木の葉の重みの下限\n",
    "             'max_depth': [1, 2, 3, 4],#決定木の最大深度(整数)\n",
    "             'colsample_bytree': [0.2, 0.5, 0.8, 1.0],#説明変数のサンプル抽出比(木)(0~1)\n",
    "             'subsample': [0.2, 0.5, 0.8, 1.0]#各決定木のサンプル抽出比(0~1)、小さいほど保守的になる\n",
    "             }\n",
    "# グリッドサーチのインスタンス作成\n",
    "#引数一覧\n",
    "#estimator: チューニングを行うモデル\n",
    "#param_grid: パラメータ候補パラメータ名: [候補リスト]\n",
    "#scoring: 評価指標(今回はneg_mean_squared_error(RSME))\n",
    "#cv: Cross Validationの分割数(default: 3)\n",
    "#verbose: ログ出力レベル\n",
    "#n_jobs: 同時実行数(-1: コア数で並列実行)\n",
    "#refit: 　trueのとき最良のパラメータで再学習\n",
    "grid_model = GridSearchCV(model, cv_params,cv = 5,\n",
    "                      scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_model.fit(features_train , target_train)\n",
    "pred = grid_model.predict(features_test)\n",
    "#評価\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "sqrt(mean_squared_error(target_test, pred)) \n",
    "#pwrカラムなし,horsepowerあり,accelerationあり;2.62\n",
    "#pwrカラムなし,horsepowerなしaccelerationあり;2.72\n",
    "#pwrカラムあり,horsepowerなし,accelerationあり;2.53\n",
    "#pwrカラムあり,horsepowerなし,accelerationなし;2.85\n",
    "#pwrカラムあり,horsepowerあり,accelerationなし;3.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル実装(train,test結合版)\n",
    "#gridsearchなし\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_train_test = pd.concat([df_train , df_test] , axis =0)\n",
    "#print(df_train_test[df_train_test['horsepower'] == \"?\"])\n",
    "df_train_test['horsepower'] = df_train_test['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train_test.iloc[24 , 4] = df_train_test[df_train_test['displacement'] == 151]['horsepower'].mean()\n",
    "#renault 18\n",
    "df_train_test.iloc[113 , 4] = df_train_test[(98 <= df_train_test['displacement']) & (df_train_test['displacement']<= 102)]['horsepower'].mean()\n",
    "#renault lecar deluxe\n",
    "df_train_test.iloc[145 , 4] = df_train_test[df_train_test['displacement'] == 85]['horsepower'].mean()\n",
    "#ford pinto\n",
    "df_train_test.iloc[175 , 4] = df_train_test[df_train_test['car name'] == 'ford pinto']['horsepower'].mean()\n",
    "#ford maverick\n",
    "df_train_test.loc[70 , 'horsepower'] = df_train_test[df_train_test['car name'] == \"ford maverick\"]['horsepower'].mean()\n",
    "#ford mustang cobra\n",
    "df_train_test.loc[112 , 'horsepower'] = df_train_test[df_train_test['displacement'] == 140]['horsepower'].mean()\n",
    "#pwrカラム作成\n",
    "df_train_test['pwr'] = df_train_test['weight']/df_train_test['horsepower']\n",
    "#ラベルエンコーディング(train,test結合版)\n",
    "#メーカーカラム作成\n",
    "df_split = df_train_test['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train_test['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train_test['manufacturers name'] = df_train_test['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "\n",
    "#エンコーディング\n",
    "df_number = pd.get_dummies(df_train_test , columns = ['origin' , 'manufacturers name'] , dtype = int)\n",
    "#print(df_number)\n",
    "df_train = df_number.iloc[:198 , :]\n",
    "df_test = df_number.iloc[199: , :]\n",
    "\n",
    "#目的変数の分離\n",
    "features_train = df_train.drop(['weight', 'id' , 'car name' , 'mpg','horsepower' , 'cylinders','acceleration'] , axis = 1)\n",
    "target_train = df_train['mpg']\n",
    "\n",
    "features_test = df_test.drop(['weight' , 'id' , 'car name' , 'mpg','horsepower' , 'cylinders','acceleration'] , axis = 1)\n",
    "#学習\n",
    "from xgboost import XGBRegressor\n",
    "#early_stopping_roundsは学習回数を適切なタイミングで打ち止めるための仕組み\n",
    "model = XGBRegressor()\n",
    "model.fit(features_train , target_train)\n",
    "\n",
    "df_pred = pd.DataFrame(model.predict(features_test))\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_pred = pd.merge(df_test['id'].astype(int) , df_pred , how = 'outer' , right_index = True , left_index=True)\n",
    "df_pred\n",
    "#評価\n",
    "df_pred.to_csv('XGBsample_submit.csv' , header = False , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    29.0\n",
      "1    31.9\n",
      "2    19.0\n",
      "3    28.0\n",
      "4    37.7\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#モデル実装(train,test結合版)\n",
    "#gridsearch版\n",
    "#欠損値補完と標準化の間にエンコーディングの操作を入れるとエラーが出てしまったため改善しよう\n",
    "#データ読み込み\n",
    "df_train = pd.read_csv('データ/train.tsv' , sep = '\\t')\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_train_test = pd.concat([df_train , df_test] , axis =0)\n",
    "#print(df_train_test[df_train_test['horsepower'] == \"?\"])\n",
    "df_train_test['horsepower'] = df_train_test['horsepower'].replace({'?':np.nan}).astype(float)\n",
    "df_train[df_train['horsepower'].isnull()]#欠損値を含むカラムの抽出\n",
    "#欠損値補完\n",
    "#amc concord dl\n",
    "df_train_test.iloc[24 , 4] = df_train_test[df_train_test['displacement'] == 151]['horsepower'].mean()\n",
    "#renault 18\n",
    "df_train_test.iloc[113 , 4] = df_train_test[(98 <= df_train_test['displacement']) & (df_train_test['displacement']<= 102)]['horsepower'].mean()\n",
    "#renault lecar deluxe\n",
    "df_train_test.iloc[145 , 4] = df_train_test[df_train_test['displacement'] == 85]['horsepower'].mean()\n",
    "#ford pinto\n",
    "df_train_test.iloc[175 , 4] = df_train_test[df_train_test['car name'] == 'ford pinto']['horsepower'].mean()\n",
    "#ford maverick\n",
    "df_train_test.loc[70 , 'horsepower'] = df_train_test[df_train_test['car name'] == \"ford maverick\"]['horsepower'].mean()\n",
    "#ford mustang cobra\n",
    "df_train_test.loc[112 , 'horsepower'] = df_train_test[df_train_test['displacement'] == 140]['horsepower'].mean()\n",
    "#pwrカラム作成\n",
    "df_train_test['pwr'] = df_train_test['weight']/df_train_test['horsepower']\n",
    "#ラベルエンコーディング(train,test結合版)\n",
    "#メーカーカラム作成\n",
    "df_split = df_train_test['car name'].str.split(expand = True)#str.split('')で文字列を''で分割(入力しないと空白で分割される)\n",
    "df_train_test['manufacturers name'] = df_split.iloc[:, 0]\n",
    "df_train_test['manufacturers name'] = df_train_test['manufacturers name'].replace({\"toyouta\":\"toyota\", \"vw\":\"volkswagen\", \"vokswagen\":\"volkswagen\",  \"chevroelt\":\"chevrolet\" ,  \"chevy\":\"chevrolet\",\"mercury\":\"ford\", \"datsun\":\"nissan\", \"maxda\":\"mazda\",  \"mercedes\":\"mercedes-benz\"})#カラム名の修正\n",
    "\n",
    "#エンコーディング\n",
    "df_number = pd.get_dummies(df_train_test , columns = ['origin' , 'manufacturers name'] , dtype = int)\n",
    "df_train = df_number.iloc[:198 , :]\n",
    "df_test = df_number.iloc[199: , :]\n",
    "\n",
    "#目的変数の分離\n",
    "features_train = df_train.drop(['weight' , 'id' , 'car name' , 'mpg' , 'cylinders','horsepower' , 'acceleration'] , axis = 1)\n",
    "target_train = df_train['mpg']\n",
    "print(target_train.head())\n",
    "features_test = df_test.drop(['weight' , 'id' , 'car name' , 'mpg'  , 'cylinders','horsepower' , 'acceleration'] , axis = 1)\n",
    "#学習\n",
    "from xgboost import XGBRegressor\n",
    "#early_stopping_roundsは学習回数を適切なタイミングで打ち止めるための仕組み\n",
    "model = XGBRegressor()\n",
    "\n",
    "#K-分割交差検証\n",
    "#交差検証は比較的少ないデータセットを使って学習する場合に、過学習を防ぐ（汎化性能を上げる）ためにする\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 最終的なパラメータ範囲\n",
    "cv_params = {'n_estimators': [20,40,60,80,100],\n",
    "             'learning_rate': [0.01, 0.03, 0.1, 0.3],#学習率(0～1)\n",
    "             'min_child_weight': [2, 4, 6, 8],#決定木の葉の重みの下限\n",
    "             'max_depth': [1, 2, 3, 4],#決定木の最大深度(整数)\n",
    "             'colsample_bytree': [0.2, 0.5, 0.8, 1.0],#説明変数のサンプル抽出比(木)(0~1)\n",
    "             'subsample': [0.2, 0.5, 0.8, 1.0]#各決定木のサンプル抽出比(0~1)、小さいほど保守的になる\n",
    "             }\n",
    "# グリッドサーチのインスタンス作成\n",
    "#引数一覧\n",
    "#estimator: チューニングを行うモデル\n",
    "#param_grid: パラメータ候補パラメータ名: [候補リスト]\n",
    "#scoring: 評価指標(今回はneg_mean_squared_error(RSME))\n",
    "#cv: Cross Validationの分割数(default: 3)\n",
    "#verbose: ログ出力レベル\n",
    "#n_jobs: 同時実行数(-1: コア数で並列実行)\n",
    "#refit: 　trueのとき最良のパラメータで再学習\n",
    "\n",
    " \n",
    "grid_model = GridSearchCV(model, cv_params,cv = cv,\n",
    "                      scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_model.fit(features_train , target_train)\n",
    "\n",
    "df_pred = pd.DataFrame(grid_model.predict(features_test))\n",
    "df_test = pd.read_csv('データ/test.tsv' , sep = '\\t')\n",
    "df_pred = pd.merge(df_test['id'].astype(int) , df_pred , how = 'outer' , right_index = True , left_index=True)\n",
    "df_pred\n",
    "#評価\n",
    "df_pred.to_csv('XGBsample_submit.csv' , header = False , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#目的変数の分離\n",
    "features_train = df_train.drop(['weight' , 'acceleration' , 'mpg' ] , axis = 1)\n",
    "target_train = df_train['mpg']\n",
    "features_test = df_test.drop(['weight' , 'acceleration'] , axis = 1)\n",
    "#学習\n",
    "from xgboost import XGBRegressor\n",
    "#early_stopping_roundsは学習回数を適切なタイミングで打ち止めるための仕組み\n",
    "model = XGBRegressor(n_estimators = 100)\n",
    "model.fit(features_train , target_train)\n",
    "#予測\n",
    "df_pred = pd.DataFrame(model.predict(features_test))\n",
    "df_test = pd.read_csv('../test.tsv' , sep = '\\t')\n",
    "df_pred = pd.merge(df_test['id'].astype(int) , df_pred , how = 'outer' , right_index = True , left_index=True)\n",
    "df_pred\n",
    "#評価\n",
    "df_pred.to_csv('XGBsample_submit.csv' , header = False , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = GridSearchCV()\n",
    "# 最終的なパラメータ範囲\n",
    "cv_params = {'n_estimators': [20,40,60,80,100],\n",
    "             'learning_rate': [0.01, 0.03, 0.1, 0.3],#学習率(0～1)\n",
    "             'min_child_weight': [2, 4, 6, 8],#決定木の葉の重みの下限\n",
    "             'max_depth': [1, 2, 3, 4],#決定木の最大深度(整数)\n",
    "             'colsample_bytree': [0.2, 0.5, 0.8, 1.0],#説明変数のサンプル抽出比(木)(0~1)\n",
    "             'subsample': [0.2, 0.5, 0.8, 1.0]#各決定木のサンプル抽出比(0~1)、小さいほど保守的になる\n",
    "             }\n",
    "# グリッドサーチのインスタンス作成\n",
    "#引数一覧\n",
    "#estimator: チューニングを行うモデル\n",
    "#param_grid: パラメータ候補パラメータ名: [候補リスト]\n",
    "#scoring: 評価指標(今回はneg_mean_squared_error(RSME))\n",
    "#cv: Cross Validationの分割数(default: 3)\n",
    "#verbose: ログ出力レベル\n",
    "#n_jobs: 同時実行数(-1: コア数で並列実行)\n",
    "#refit: 　trueのとき最良のパラメータで再学習\n",
    "grid_model = GridSearchCV(model, cv_params,cv = 5,\n",
    "                      scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_model.fit(features_train , target_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
