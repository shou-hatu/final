{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn_analyzer import regplot\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 使用するチューニング対象外のパラメータ\n",
    "params = {\n",
    "    'objective': 'regression',  # 最小化させるべき損失関数\n",
    "    'metric': 'rmse',  # 学習時に使用する評価指標(early_stoppingの評価指標にも同じ値が使用される)\n",
    "    'random_state': seed,  # 乱数シード\n",
    "    'boosting_type': 'gbdt',  # boosting_type\n",
    "    'n_estimators': 10000,  # 最大学習サイクル数。early_stopping使用時は大きな値を入力\n",
    "    'verbose': -1,  # これを指定しないと`No further splits with positive gain, best gain: -inf`というWarningが表示される\n",
    "    'early_stopping_round': 10  # ここでearly_stoppingを指定\n",
    "    }\n",
    "# モデル作成\n",
    "model = LGBMRegressor(**params)\n",
    "\n",
    "# 学習時fitパラメータ指定 (early_stopping用のデータeval_setを渡す)\n",
    "fit_params = {\n",
    "    'eval_set': [(X_eval, y_eval)]\n",
    "    }\n",
    "scoring = 'neg_root_mean_squared_error'  # 評価指標をRMSEに指定\n",
    "# クロスバリデーションで評価指標算出\n",
    "scores = cross_val_score(model, X_cv, y_cv, cv=cv,\n",
    "                         scoring=scoring, n_jobs=-1, fit_params=fit_params)\n",
    "# クロスバリデーションして予測値ヒートマップを可視化\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=seed)  # KFoldでクロスバリデーション分割指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "cv_params = {'reg_alpha': [0, 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
    "             'reg_lambda': [0, 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
    "             'num_leaves': [2, 4, 8, 16, 32, 64, 96, 128, 160, 192, 224, 256],\n",
    "             'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "             'subsample_freq': [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "             'min_child_samples': [0, 2, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "             }\n",
    "param_scales = {'reg_alpha': 'log',\n",
    "                'reg_lambda': 'log',\n",
    "                'num_leaves': 'linear',\n",
    "                'colsample_bytree': 'linear',\n",
    "                'subsample': 'linear',\n",
    "                'subsample_freq': 'linear',\n",
    "                'min_child_samples': 'linear'\n",
    "                }\n",
    "# 検証曲線のプロット（パラメータ毎にプロット）\n",
    "model.set_params(min_child_samples=5, num_leaves=2)\n",
    "for i, (k, v) in enumerate(cv_params.items()):\n",
    "    train_scores, valid_scores = validation_curve(estimator=model,\n",
    "                                                  X=X_cv, y=y_cv,\n",
    "                                                  param_name=k,\n",
    "                                                  param_range=v,\n",
    "                                                  fit_params=fit_params,\n",
    "                                                  cv=cv, scoring=scoring,\n",
    "                                                  n_jobs=-1)\n",
    "    # 学習データに対するスコアの平均±標準偏差を算出\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std  = np.std(train_scores, axis=1)\n",
    "    train_center = train_mean\n",
    "    train_high = train_mean + train_std\n",
    "    train_low = train_mean - train_std\n",
    "    # テストデータに対するスコアの平均±標準偏差を算出\n",
    "    valid_mean = np.mean(valid_scores, axis=1)\n",
    "    valid_std  = np.std(valid_scores, axis=1)\n",
    "    valid_center = valid_mean\n",
    "    valid_high = valid_mean + valid_std\n",
    "    valid_low = valid_mean - valid_std\n",
    "    # training_scoresをプロット\n",
    "    plt.plot(v, train_center, color='blue', marker='o', markersize=5, label='training score')\n",
    "    plt.fill_between(v, train_high, train_low, alpha=0.15, color='blue')\n",
    "    # validation_scoresをプロット\n",
    "    plt.plot(v, valid_center, color='green', linestyle='--', marker='o', markersize=5, label='validation score')\n",
    "    plt.fill_between(v, valid_high, valid_low, alpha=0.15, color='green')\n",
    "    # スケールをparam_scalesに合わせて変更\n",
    "    plt.xscale(param_scales[k])\n",
    "    # 軸ラベルおよび凡例の指定\n",
    "    plt.xlabel(k)  # パラメータ名を横軸ラベルに\n",
    "    plt.ylabel(scoring)  # スコア名を縦軸ラベルに\n",
    "    plt.legend(loc='lower right')  # 凡例\n",
    "    # グラフを描画\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "start = time.time()\n",
    "# ベイズ最適化時の評価指標算出メソッド\n",
    "def bayes_objective(trial):\n",
    "    params = {\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 0.1, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 6),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 0, 10)\n",
    "    }\n",
    "    # モデルにパラメータ適用\n",
    "    model.set_params(**params)\n",
    "    # cross_val_scoreでクロスバリデーション\n",
    "    scores = cross_val_score(model, X, y, cv=cv,\n",
    "                             scoring=scoring, fit_params=fit_params, n_jobs=-1)\n",
    "    val = scores.mean()\n",
    "    return val\n",
    "\n",
    "# ベイズ最適化を実行\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "study.optimize(bayes_objective, n_trials=400)\n",
    "\n",
    "# 最適パラメータの表示と保持\n",
    "best_params = study.best_trial.params\n",
    "best_score = study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
